import os
import tempfile
import uuid
import wave
import threading
voice_lock = threading.Lock()
import gradio as gr
from PIL import Image, ImageDraw, ImageFont
import json
from datetime import datetime
import math
import gc
import threading
import time
import re
import matplotlib

matplotlib.use('Agg')
import matplotlib.pyplot as plt
import numpy as np
from PIL import ImageEnhance

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["GRADIO_ANALYTICS_ENABLED"] = "False"

TITLE = "ğŸŒ½ æ™ºèƒ½å†œä¸šåŠ©æ‰‹"
DESCRIPTION = "ç‰ç±³å»é›„æ™ºèƒ½è¯†åˆ«ä¸æŒ‡å¯¼ç³»ç»Ÿ"

# å¯¼å…¥æ¨¡å—
from smart_agriculture_llm import agriculture_llm

# æ£€æµ‹å†å²å­˜å‚¨
detection_history = []

# çŸ¥è¯†å›¾è°±å†å²å­˜å‚¨
knowledge_graph_history = []

# è¯­éŸ³å¤„ç†å™¨ï¼ˆæ‡’åŠ è½½ï¼‰
_speech_processor = None

# æ€§èƒ½ç›‘æ§
performance_stats = {
    "last_cleanup": datetime.now(),
    "generated_files": set(),
    "active_threads": 0
}

# å…¨å±€å­—ä½“ç¼“å­˜
_font_cache = None
_font_small_cache = None


# çŸ¥è¯†å›¾è°±ç›¸å…³å‡½æ•°
def save_knowledge_graph_record(question, answer, kg_image_path):
    """ä¿å­˜çŸ¥è¯†å›¾è°±è®°å½•"""
    if not kg_image_path or not os.path.exists(kg_image_path):
        return None

    record = {
        'id': str(uuid.uuid4()),
        'timestamp': datetime.now().isoformat(),
        'question': question,
        'answer': answer[:200] + "..." if len(answer) > 200 else answer,  # æˆªæ–­é•¿ç­”æ¡ˆ
        'kg_image': kg_image_path
    }
    knowledge_graph_history.append(record)

    # é™åˆ¶å†å²è®°å½•æ•°é‡ï¼Œé¿å…å†…å­˜æ³„æ¼
    if len(knowledge_graph_history) > 100:
        oldest_record = knowledge_graph_history.pop(0)
        # æ¸…ç†æ—§æ–‡ä»¶
        try:
            if os.path.exists(oldest_record['kg_image']):
                os.remove(oldest_record['kg_image'])
        except:
            pass

    return record


def get_knowledge_graph_gallery():
    """è·å–çŸ¥è¯†å›¾è°±ç”»å»Šæ•°æ®"""
    if not knowledge_graph_history:
        return [], "æš‚æ— çŸ¥è¯†å›¾è°±è®°å½•"

    gallery_data = []
    for record in reversed(knowledge_graph_history[-20:]):  # åªæ˜¾ç¤ºæœ€è¿‘20ä¸ª
        if os.path.exists(record['kg_image']):
            gallery_data.append((record['kg_image'], f"Q: {record['question'][:30]}..."))

    return gallery_data, f"å…± {len(knowledge_graph_history)} ä¸ªçŸ¥è¯†å›¾è°±"


def get_knowledge_graph_detail(kg_image_path):
    """è·å–çŸ¥è¯†å›¾è°±è¯¦ç»†ä¿¡æ¯"""
    if not kg_image_path:
        return "è¯·é€‰æ‹©çŸ¥è¯†å›¾è°±", "", ""

    for record in knowledge_graph_history:
        if record['kg_image'] == kg_image_path:
            return record['question'], record['answer'], record['timestamp']

    return "æœªæ‰¾åˆ°è¯¦ç»†ä¿¡æ¯", "", ""


def cleanup_old_files():
    """æ¸…ç†æ—§æ–‡ä»¶ï¼Œé‡Šæ”¾èµ„æº"""
    try:
        current_time = datetime.now()
        if (current_time - performance_stats["last_cleanup"]).seconds < 300:
            return

        print("ğŸ§¹ æ¸…ç†æ—§æ–‡ä»¶...")
        temp_dir = tempfile.gettempdir()

        # æ¸…ç†ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶ï¼ˆä¿ç•™çŸ¥è¯†å›¾è°±æ–‡ä»¶ï¼‰
        kg_files = {record['kg_image'] for record in knowledge_graph_history}

        for filename in performance_stats["generated_files"].copy():
            filepath = os.path.join(temp_dir, filename)
            if os.path.exists(filepath) and filepath not in kg_files:
                try:
                    file_time = datetime.fromtimestamp(os.path.getctime(filepath))
                    if (current_time - file_time).seconds > 600:
                        os.remove(filepath)
                        performance_stats["generated_files"].remove(filename)
                        print(f"ğŸ—‘ï¸ åˆ é™¤æ—§æ–‡ä»¶: {filename}")
                except Exception as e:
                    print(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {filename}: {e}")

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        performance_stats["last_cleanup"] = current_time
        print("âœ… æ¸…ç†å®Œæˆ")

    except Exception as e:
        print(f"æ¸…ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")


def get_speech_processor():
    """è·å–è¯­éŸ³å¤„ç†å™¨å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global _speech_processor
    if _speech_processor is None:
        try:
            from speech_processor import speech_processor as sp
            _speech_processor = sp
            print("âœ… è¯­éŸ³å¤„ç†å™¨åŠ è½½æˆåŠŸ")

            # æµ‹è¯•è¯­éŸ³åˆæˆå¼•æ“
            if _speech_processor.tts_engine:
                print("âœ… è¯­éŸ³åˆæˆå¼•æ“å¯ç”¨")
            else:
                print("âŒ è¯­éŸ³åˆæˆå¼•æ“ä¸å¯ç”¨")

        except Exception as e:
            print(f"âŒ è¯­éŸ³å¤„ç†å™¨åŠ è½½å¤±è´¥: {e}")

            # åˆ›å»ºæ”¹è¿›çš„è™šæ‹Ÿè¯­éŸ³å¤„ç†å™¨
            class DummySpeechProcessor:
                def __init__(self):
                    self.tts_engine = None
                    print("âš ï¸ ä½¿ç”¨è™šæ‹Ÿè¯­éŸ³å¤„ç†å™¨")

                def speech_to_text(self, audio_file):
                    return "è¯­éŸ³è¯†åˆ«åŠŸèƒ½æš‚ä¸å¯ç”¨ï¼Œè¯·ä½¿ç”¨æ–‡æœ¬è¾“å…¥"

                def text_to_speech(self, text, save_to_file=False):
                    print(f"ğŸ”Š è™šæ‹Ÿè¯­éŸ³åˆæˆ: {text[:50]}...")
                    if save_to_file:
                        # åˆ›å»ºä¸€ä¸ªç©ºçš„éŸ³é¢‘æ–‡ä»¶ä½œä¸ºå ä½ç¬¦
                        temp_file = os.path.join(tempfile.gettempdir(), f"tts_dummy_{uuid.uuid4().hex}.wav")
                        # åˆ›å»ºä¸€ä¸ªç©ºçš„WAVæ–‡ä»¶
                        with wave.open(temp_file, 'wb') as wf:
                            wf.setnchannels(1)
                            wf.setsampwidth(2)
                            wf.setframerate(16000)
                            wf.writeframes(b'')
                        print(f"ğŸ“ åˆ›å»ºè™šæ‹ŸéŸ³é¢‘æ–‡ä»¶: {temp_file}")
                        return temp_file
                    return None

            _speech_processor = DummySpeechProcessor()
    return _speech_processor


def save_detection_record(detection_data, area_info=""):
    """ä¿å­˜æ£€æµ‹è®°å½•"""
    record = {
        'id': str(uuid.uuid4()),
        'timestamp': datetime.now().isoformat(),
        'area': area_info,
        'data': detection_data
    }
    detection_history.append(record)

    # é™åˆ¶å†å²è®°å½•æ•°é‡ï¼Œé¿å…å†…å­˜æ³„æ¼
    if len(detection_history) > 50:
        detection_history.pop(0)

    return record


def preprocess_image(img):
    """é¢„å¤„ç†å›¾åƒï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®"""
    if img is None:
        return None

    try:
        # å¦‚æœå·²ç»æ˜¯PILå›¾åƒï¼Œç›´æ¥è¿”å›
        if isinstance(img, Image.Image):
            return img

        # å¦‚æœæ˜¯numpyæ•°ç»„ï¼Œè½¬æ¢ä¸ºPILå›¾åƒ
        import numpy as np
        if isinstance(img, np.ndarray):
            # ç¡®ä¿æ˜¯uint8ç±»å‹
            if img.dtype != np.uint8:
                img = img.astype(np.uint8)
            return Image.fromarray(img)

        # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œæ‰“å¼€å›¾åƒ
        if isinstance(img, str) and os.path.exists(img):
            return Image.open(img)

        # å¦‚æœæ˜¯Gradioæ–‡ä»¶å¯¹è±¡
        if hasattr(img, 'name') and os.path.exists(img.name):
            return Image.open(img.name)

    except Exception as e:
        print(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
        return None

    return None


def safe_image_save(image, path, quality=85):
    """å®‰å…¨ä¿å­˜å›¾åƒï¼Œé¿å…æƒé™é—®é¢˜"""
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(path), exist_ok=True)
        image.save(path, quality=quality, optimize=True)

        # è®°å½•ç”Ÿæˆçš„æ–‡ä»¶
        filename = os.path.basename(path)
        performance_stats["generated_files"].add(filename)

        return path
    except Exception as e:
        print(f"ä¿å­˜å›¾åƒå¤±è´¥: {e}")
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ä½œä¸ºå¤‡é€‰
        temp_path = os.path.join(tempfile.gettempdir(), f"{uuid.uuid4().hex}.jpg")
        image.save(temp_path, quality=quality, optimize=True)

        filename = os.path.basename(temp_path)
        performance_stats["generated_files"].add(filename)

        return temp_path


def fast_inference(img, threshold, area_info, enable_guidance):
    """å¿«é€Ÿæ£€æµ‹æ¨ç†å‡½æ•° - ä¼˜åŒ–å¤„ç†é€Ÿåº¦"""
    processed_img = preprocess_image(img)
    if processed_img is None:
        return None, "è¯·å…ˆä¸Šä¼ æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶", ""

    try:
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = datetime.now()

        # æ‰§è¡Œæ£€æµ‹
        from Stamen_detection import detect_stamen
        boxed_pil, detection_result = detect_stamen(processed_img, threshold)

        # è®¡ç®—å¤„ç†æ—¶é—´
        process_time = (datetime.now() - start_time).total_seconds()

        # ç”Ÿæˆæ£€æµ‹ç»“æœæ–‡æœ¬
        detection_text = detection_result.to_text_summary()

        # æ·»åŠ ä½ç½®ä¿¡æ¯
        if hasattr(detection_result, 'to_position_summary'):
            position_text = detection_result.to_position_summary()
            full_detection_text = f"{detection_text}\n\n{position_text}"
        else:
            full_detection_text = detection_text

        # æ·»åŠ å¤„ç†æ—¶é—´ä¿¡æ¯
        full_detection_text = f"â±ï¸ å¤„ç†æ—¶é—´: {process_time:.2f}ç§’\n\n{full_detection_text}"

        # ä¿å­˜æ£€æµ‹è®°å½•
        detection_data = detection_result.get_detection_data()
        save_detection_record(detection_data, area_info)

        # ç”Ÿæˆæ“ä½œæŒ‡å¯¼ - ä½¿ç”¨çº¿ç¨‹é¿å…é˜»å¡
        guidance_text = ""

        if enable_guidance and detection_result.detected_objects:
            try:
                # ä½¿ç”¨çº¿ç¨‹ç”ŸæˆæŒ‡å¯¼ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
                def generate_guidance_thread():
                    nonlocal guidance_text
                    try:
                        guidance_prompt = f"""
æ£€æµ‹ç»“æœï¼š{detection_text}

è¯·ç›´æ¥ç»™å‡ºå…·ä½“çš„å»é›„æ“ä½œæŒ‡å¯¼ï¼Œè¦æ±‚ï¼š
- ç›´æ¥ç»™å‡ºæ“ä½œæ­¥éª¤ï¼Œä¸è¦æœ‰ä»»ä½•æ€è€ƒè¿‡ç¨‹
- æ­¥éª¤æ¸…æ™°å®ç”¨ï¼Œæ˜“äºæ‰§è¡Œ
- åŸºäºæ£€æµ‹ç»“æœé’ˆå¯¹æ€§å»ºè®®
- ä½¿ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€
- ä¸è¶…è¿‡5ä¸ªæ­¥éª¤

æ“ä½œæŒ‡å¯¼ï¼š
"""
                        guidance_response = agriculture_llm.get_expert_answer(guidance_prompt, detection_text)
                        guidance_text = clean_ai_response(guidance_response)
                    except Exception as e:
                        print(f"ç”ŸæˆæŒ‡å¯¼å¤±è´¥: {e}")
                        guidance_text = "AIæŒ‡å¯¼æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·å‚è€ƒæ ‡å‡†æ“ä½œæµç¨‹ã€‚"

                # å¯åŠ¨çº¿ç¨‹ï¼Œä½†è®¾ç½®è¶…æ—¶
                guidance_thread = threading.Thread(target=generate_guidance_thread)
                guidance_thread.daemon = True
                guidance_thread.start()
                guidance_thread.join(timeout=10)  # 10ç§’è¶…æ—¶

                if guidance_thread.is_alive():
                    guidance_text = "æ“ä½œæŒ‡å¯¼ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"

            except Exception as e:
                print(f"ç”ŸæˆæŒ‡å¯¼å¤±è´¥: {e}")
                guidance_text = "AIæŒ‡å¯¼æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·å‚è€ƒæ ‡å‡†æ“ä½œæµç¨‹ã€‚"

        # ä¿å­˜ç»“æœå›¾åƒ
        out_path = os.path.join(tempfile.gettempdir(), f"{uuid.uuid4().hex}.jpg")
        out_path = safe_image_save(boxed_pil, out_path, quality=85)

        print(f"å¿«é€Ÿæ£€æµ‹å®Œæˆï¼Œå‘ç° {len(detection_result.detected_objects)} ä¸ªé›„è•Šï¼Œè€—æ—¶ {process_time:.2f}ç§’")
        return out_path, full_detection_text, guidance_text

    except Exception as e:
        error_msg = f"æ£€æµ‹å¤±è´¥: {str(e)}"
        print(f"é”™è¯¯è¯¦æƒ…: {e}")

        # æä¾›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        if "timeout" in str(e).lower() or "è¶…æ—¶" in str(e):
            error_msg += "\n\nå»ºè®®ï¼šç½‘ç»œè¿æ¥è¾ƒæ…¢ï¼Œè¯·ç¨åé‡è¯•"
        elif "network" in str(e).lower() or "è¿æ¥" in str(e):
            error_msg += "\n\nå»ºè®®ï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•"
        else:
            error_msg += "\n\nå»ºè®®ï¼šè¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ"

        return None, error_msg, ""


def clean_ai_response(response):
    """å½»åº•æ¸…ç†AIå“åº”ï¼Œå»é™¤æ‰€æœ‰æ€è€ƒè¿‡ç¨‹å’Œå†…éƒ¨æ¨ç†"""
    if not response:
        return response

    # å®šä¹‰éœ€è¦è¿‡æ»¤çš„æ€è€ƒæ¨¡å¼å…³é”®è¯
    thought_patterns = [
        'ç”¨æˆ·é—®çš„æ˜¯', 'æ ¹æ®æä¾›çš„', 'æ£€æµ‹æ•°æ®é‡Œæåˆ°', 'æ‰€ä»¥ç›´æ¥å›ç­”',
        'ä¸éœ€è¦é¢å¤–è§£é‡Š', 'æŒ‰ç…§è¦æ±‚', 'è¿™éƒ¨åˆ†æ˜æ˜¾', 'å¯èƒ½è¿˜è¦è€ƒè™‘',
        'éœ€è¦ç¡®ä¿', 'å¯èƒ½å­˜åœ¨çš„é—®é¢˜', 'æ”¹è¿›å»ºè®®åŒ…æ‹¬', 'ä¸‹ä¸€æ­¥å·¥ä½œè®¡åˆ’',
        'ç”¨æˆ·è¦æ±‚', 'éœ€è¦ç¡®ä¿æ¯ä¸ªéƒ¨åˆ†', 'åŒæ—¶è¦é¿å…', 'ç›´æ¥åˆ—å‡ºåˆ†æç»“æœ',
        'æ€è€ƒï¼š', 'åˆ†æï¼š', 'æ¨ç†ï¼š', 'é¦–å…ˆ', 'ç„¶å', 'æ¥ç€', 'æœ€å',
        'åŸºäºä»¥ä¸Š', 'ç»¼ä¸Šæ‰€è¿°', 'æ€»è€Œè¨€ä¹‹', 'å› æ­¤', 'æ‰€ä»¥', 'å› è€Œ',
        'ä»æ•°æ®å¯ä»¥çœ‹å‡º', 'æ ¹æ®åˆ†æç»“æœ', 'æˆ‘è®¤ä¸º', 'æˆ‘å»ºè®®', 'æˆ‘çš„çœ‹æ³•æ˜¯',
        'è®©æˆ‘ä»¬æ¥', 'æ¥ä¸‹æ¥æˆ‘ä»¬', 'ç°åœ¨å¼€å§‹', 'å¼€å§‹å›ç­”', 'å›ç­”å¦‚ä¸‹',
        'æ“ä½œæŒ‡å¯¼éƒ¨åˆ†', 'æ­¥éª¤è¦ç®€çŸ­å®ç”¨', 'è¿™éƒ¨åˆ†æ‰æ˜¯å›ç­”', 'ç»¼åˆæ£€æµ‹æŠ¥å‘Šéƒ¨åˆ†',
        'é›„è•Šåˆ†å¸ƒç‰¹ç‚¹åˆ†æ', 'å¯èƒ½å­˜åœ¨çš„é—®é¢˜æ–¹é¢', 'æ”¹è¿›å»ºè®®åŒ…æ‹¬', 'ä¸‹ä¸€æ­¥å·¥ä½œè®¡åˆ’éœ€è¦'
    ]

    lines = response.split('\n')
    cleaned_lines = []
    in_thought_process = False

    for line in lines:
        line = line.strip()

        # è·³è¿‡ç©ºè¡Œ
        if not line:
            continue

        # æ£€æµ‹æ˜¯å¦è¿›å…¥æ€è€ƒè¿‡ç¨‹æ®µè½
        if any(pattern in line for pattern in thought_patterns):
            in_thought_process = True
            continue

        # å¦‚æœæ£€æµ‹åˆ°å®é™…å†…å®¹å¼€å§‹ï¼Œé‡ç½®çŠ¶æ€
        if line and not in_thought_process:
            # è·³è¿‡æ•°å­—åºå·ä½†ä¿ç•™å†…å®¹ï¼ˆå¦‚"1. "å˜æˆç©ºï¼‰
            if re.match(r'^\d+\.\s', line):
                line = re.sub(r'^\d+\.\s', '', line)
            cleaned_lines.append(line)
        elif in_thought_process and line and not any(pattern in line for pattern in thought_patterns):
            # å¦‚æœé‡åˆ°æ–°æ®µè½ï¼Œé€€å‡ºæ€è€ƒè¿‡ç¨‹æ¨¡å¼
            in_thought_process = False
            cleaned_lines.append(line)

    result = '\n'.join(cleaned_lines)

    # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œè¿”å›åŸå§‹å“åº”ä½†è¿›è¡ŒåŸºç¡€æ¸…ç†
    if not result.strip():
        # åŸºç¡€æ¸…ç†ï¼šç§»é™¤æ˜æ˜¾çš„æ€è€ƒæ ‡è®°
        result = re.sub(r'æ€è€ƒï¼š.*?\n', '', response)
        result = re.sub(r'åˆ†æï¼š.*?\n', '', result)
        result = re.sub(r'æ¨ç†ï¼š.*?\n', '', result)

    return result.strip()


def draw_arrow_simple(draw, x1, y1, x2, y2, color=(100, 100, 100)):
    """ç®€åŒ–çš„ç®­å¤´ç»˜åˆ¶"""
    # è®¡ç®—æ–¹å‘
    dx, dy = x2 - x1, y2 - y1
    length = (dx ** 2 + dy ** 2) ** 0.5
    if length == 0:
        return

    # å½’ä¸€åŒ–
    dx, dy = dx / length, dy / length

    # ç®­å¤´ä½ç½®ï¼ˆç¨å¾®å‘å†…ï¼‰
    arrow_x = x2 - dx * 15
    arrow_y = y2 - dy * 15

    # ç»˜åˆ¶ç®­å¤´ä¸‰è§’å½¢
    size = 8
    perpendicular_x = -dy * size
    perpendicular_y = dx * size

    points = [
        (arrow_x, arrow_y),
        (arrow_x - dx * size + perpendicular_x, arrow_y - dy * size + perpendicular_y),
        (arrow_x - dx * size - perpendicular_x, arrow_y - dy * size - perpendicular_y)
    ]

    draw.polygon(points, fill=color)


def get_fonts():
    """è·å–å­—ä½“ - ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åŠ è½½ï¼Œä¼˜å…ˆä¸­æ–‡å­—ä½“"""
    global _font_cache, _font_small_cache

    if _font_cache is not None and _font_small_cache is not None:
        return _font_cache, _font_small_cache

    try:
        from PIL import ImageFont

        # ä¼˜å…ˆå°è¯•ä¸­æ–‡å­—ä½“
        chinese_font_paths = [
            "C:/Windows/Fonts/simsun.ttc",  # Windows å®‹ä½“
            "C:/Windows/Fonts/simhei.ttf",  # Windows é»‘ä½“
            "C:/Windows/Fonts/msyh.ttc",  # Windows å¾®è½¯é›…é»‘
            "/System/Library/Fonts/PingFang.ttc",  # macOS
            "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",  # Linux
        ]

        font_loaded = False
        for font_path in chinese_font_paths:
            if os.path.exists(font_path):
                try:
                    _font_cache = ImageFont.truetype(font_path, 16)
                    _font_small_cache = ImageFont.truetype(font_path, 12)
                    print(f"âœ… ä¸­æ–‡å­—ä½“åŠ è½½æˆåŠŸ: {font_path}")
                    font_loaded = True
                    break
                except Exception as e:
                    print(f"å­—ä½“åŠ è½½å¤±è´¥ {font_path}: {e}")
                    continue

        # å¦‚æœä¸­æ–‡å­—ä½“éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
        if not font_loaded:
            try:
                _font_cache = ImageFont.load_default()
                _font_small_cache = ImageFont.load_default()
                print("âš ï¸ ä½¿ç”¨é»˜è®¤å­—ä½“ï¼ˆå¯èƒ½ä¸æ”¯æŒä¸­æ–‡ï¼‰")
            except:
                _font_cache = None
                _font_small_cache = None

    except Exception as e:
        print(f"å­—ä½“ç³»ç»ŸåŠ è½½å¤±è´¥: {e}")
        _font_cache = None
        _font_small_cache = None

    return _font_cache, _font_small_cache


def get_detection_context():
    """è·å–å½“å‰æ£€æµ‹ä¸Šä¸‹æ–‡æ•°æ®"""
    if not detection_history:
        return "æš‚æ— æ£€æµ‹æ•°æ®ï¼Œè¯·å…ˆè¿›è¡Œå›¾åƒæ£€æµ‹"

    try:
        # è·å–æœ€æ–°çš„æ£€æµ‹ç»“æœ
        latest_record = detection_history[-1]
        detection_data = latest_record['data']

        # æ„å»ºæ£€æµ‹ä¸Šä¸‹æ–‡
        context_parts = []

        # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
        if 'total_count' in detection_data:
            context_parts.append(f"æ£€æµ‹åˆ°é›„è•Šæ•°é‡: {detection_data['total_count']}ä¸ª")

        if 'detected_objects' in detection_data:
            objects = detection_data['detected_objects']
            if objects:
                # ä½ç½®ä¿¡æ¯
                positions = []
                for obj in objects[:5]:  # åªå–å‰5ä¸ªé¿å…å¤ªé•¿
                    if 'position' in obj:
                        pos = obj['position']
                        positions.append(f"({pos.get('x', 0):.1f}, {pos.get('y', 0):.1f})")

                if positions:
                    context_parts.append(f"é›„è•Šä½ç½®: {', '.join(positions)}")

        # ç½®ä¿¡åº¦ä¿¡æ¯
        if 'confidence_scores' in detection_data:
            confidences = detection_data['confidence_scores']
            if confidences:
                avg_confidence = sum(confidences) / len(confidences)
                context_parts.append(f"å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.2f}")

        # åŒºåŸŸä¿¡æ¯
        area = latest_record.get('area', '')
        if area:
            context_parts.append(f"æ£€æµ‹åŒºåŸŸ: {area}")

        return " | ".join(context_parts) if context_parts else "æ£€æµ‹æ•°æ®å¯ç”¨ä½†ä¿¡æ¯è¾ƒå°‘"

    except Exception as e:
        print(f"è·å–æ£€æµ‹ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        return "æ£€æµ‹æ•°æ®è§£æå¤±è´¥"

# æ·»åŠ ç¼ºå¤±çš„å‡½æ•°
def update_detection_status():
    """æ›´æ–°æ£€æµ‹çŠ¶æ€æ˜¾ç¤º"""
    context = get_detection_context()
    return f"ğŸ“Š å½“å‰æ£€æµ‹çŠ¶æ€: {context}"

def handle_voice_question_with_context(audio_file, enable_voice_answer, generate_kg):
    """å¤„ç†è¯­éŸ³æé—® - ç»“åˆæ£€æµ‹ä¸Šä¸‹æ–‡ï¼Œä¿®å¤è¯­éŸ³åˆæˆ"""
    if audio_file is None:
        return "è¯·å…ˆå½•åˆ¶è¯­éŸ³é—®é¢˜", None, None, "", ""

    try:
        # è¯­éŸ³è½¬æ–‡æœ¬
        speech_processor = get_speech_processor()
        question_text = speech_processor.speech_to_text(audio_file)
        print(f"è¯­éŸ³è¯†åˆ«ç»“æœ: {question_text}")

        if not question_text or "æœªè¯†åˆ«" in question_text or "æš‚ä¸å¯ç”¨" in question_text:
            return "è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡æ–°å½•åˆ¶æˆ–ä½¿ç”¨æ–‡æœ¬è¾“å…¥", None, None, "", question_text

        # è·å–æ£€æµ‹ä¸Šä¸‹æ–‡
        detection_context = get_detection_context()
        print(f"æ£€æµ‹ä¸Šä¸‹æ–‡: {detection_context}")

        # æ„å»ºæ™ºèƒ½æç¤ºè¯ï¼Œç»“åˆæ£€æµ‹æ•°æ®
        enhanced_prompt = f"""
ç”¨æˆ·æé—®ï¼š{question_text}

å½“å‰æ£€æµ‹æ•°æ®ï¼š{detection_context}

è¯·ç»“åˆæ£€æµ‹æ•°æ®ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚è¦æ±‚ï¼š
- ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œä¸è¦æœ‰ä»»ä½•æ€è€ƒè¿‡ç¨‹æˆ–è§£é‡Š
- ç®€æ´æ˜äº†ï¼Œå›ç­”æ ¸å¿ƒé—®é¢˜
- å¦‚æœä½¿ç”¨æ£€æµ‹æ•°æ®ï¼Œè¯·æ˜ç¡®æŒ‡å‡º
- æä¾›å®ç”¨çš„æ“ä½œå»ºè®®
- å¯ä»¥é€‚å½“æ‰©å±•ä¸“ä¸šçŸ¥è¯†
- ä½¿ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€

ç›´æ¥ç»™å‡ºå›ç­”ï¼š
"""

        # ä½¿ç”¨å¢å¼ºçš„æç¤ºè¯è·å–å›ç­”
        answer_response = agriculture_llm.get_expert_answer(enhanced_prompt, question_text)
        # æ¸…ç†å“åº”ï¼Œå»é™¤æ€è€ƒè¿‡ç¨‹
        answer = clean_ai_response(answer_response)

        print(f"âœ… AIå›ç­”ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(answer)}")

        # è¯­éŸ³å›ç­”
        audio_file_output = None
        if enable_voice_answer and answer:
            print("ğŸ”Š å¼€å§‹è¯­éŸ³åˆæˆ...")
            try:
                speech_processor = get_speech_processor()
                if speech_processor and hasattr(speech_processor, 'tts_engine') and speech_processor.tts_engine:
                    audio_result = [None]

                    # åœ¨ handle_question_with_context å’Œ handle_voice_question_with_context ä¸­
                    # ä¿®æ”¹è¯­éŸ³åˆæˆéƒ¨åˆ†ï¼š

                    def generate_audio():
                        try:
                            speech_processor = get_speech_processor()
                            # ä½¿ç”¨ä¿®å¤åçš„ text_to_speech æ–¹æ³•
                            audio_file_path = speech_processor.text_to_speech(answer, save_to_file=True)
                            if audio_file_path and os.path.exists(audio_file_path):
                                filename = os.path.basename(audio_file_path)
                                performance_stats["generated_files"].add(filename)
                                audio_result[0] = audio_file_path
                                print(f"âœ… è¯­éŸ³æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {audio_file_path}")
                            else:
                                print("âŒ è¯­éŸ³æ–‡ä»¶ç”Ÿæˆå¤±è´¥")
                        except Exception as e:
                            print(f"âŒ è¯­éŸ³ç”Ÿæˆçº¿ç¨‹å¼‚å¸¸: {e}")

                    audio_thread = threading.Thread(target=generate_audio)
                    audio_thread.daemon = True
                    audio_thread.start()
                    audio_thread.join(timeout=15)

                    audio_file_output = audio_result[0]

                    if not audio_file_output:
                        print("âš ï¸ è¯­éŸ³ç”Ÿæˆè¶…æ—¶æˆ–å¤±è´¥")
                else:
                    print("âŒ è¯­éŸ³åˆæˆå¼•æ“ä¸å¯ç”¨")
            except Exception as e:
                print(f"âŒ è¯­éŸ³åˆæˆå¤„ç†å¤±è´¥: {e}")

        # çŸ¥è¯†å›¾è°±ç”Ÿæˆ - ä¿®æ”¹ä¸ºä¿å­˜åˆ°å†å²è®°å½•
        kg_status = ""
        if generate_kg and answer:
            try:
                kg_image, kg_status = generate_knowledge_graph_optimized(question_text, answer)
                if kg_image:
                    # ä¿å­˜åˆ°çŸ¥è¯†å›¾è°±å†å²è®°å½•
                    save_knowledge_graph_record(question_text, answer, kg_image)
                    kg_status = "âœ… çŸ¥è¯†å›¾è°±å·²ç”Ÿæˆå¹¶ä¿å­˜åˆ°çŸ¥è¯†å›¾è°±åº“"
                else:
                    kg_status = "âŒ çŸ¥è¯†å›¾è°±ç”Ÿæˆå¤±è´¥"
            except Exception as e:
                print(f"çŸ¥è¯†å›¾è°±ç”Ÿæˆå¤±è´¥: {e}")
                kg_status = "çŸ¥è¯†å›¾è°±ç”Ÿæˆå¤±è´¥"
        else:
            kg_status = "æœªå¯ç”¨çŸ¥è¯†å›¾è°±ç”Ÿæˆ"

        # è§¦å‘æ¸…ç†
        cleanup_old_files()

        return answer, audio_file_output, None, kg_status, question_text  # è¿”å›Noneç»™kg_image

    except Exception as e:
        print(f"è¯­éŸ³é—®é¢˜å¤„ç†å¤±è´¥: {e}")
        return f"è¯­éŸ³å¤„ç†å¤±è´¥: {str(e)}", None, None, "", ""


def generate_knowledge_graph_optimized(question, answer):
    """ç”Ÿæˆå†œä¸šçŸ¥è¯†å›¾è°± - ä¼˜åŒ–æ€§èƒ½ç‰ˆæœ¬ï¼Œä¿®å¤å­—ä½“é—®é¢˜"""
    if not question.strip() or not answer.strip():
        return None, "è¯·å…ˆæé—®å¹¶è·å¾—ç­”æ¡ˆ"

    try:
        # æ”¹è¿›çš„æç¤ºè¯ï¼Œç¡®ä¿ä¸åŒé—®é¢˜ç”Ÿæˆä¸åŒçš„çŸ¥è¯†å›¾è°±
        kg_prompt = f"""
åŸºäºä»¥ä¸‹é—®ç­”å†…å®¹ï¼Œæå–3-5ä¸ªæ ¸å¿ƒæ¦‚å¿µåŠå…¶å…³ç³»ï¼š

é—®é¢˜ï¼š{question}
ç­”æ¡ˆï¼š{answer}

è¯·ç›´æ¥è¿”å›å…³ç³»å¯¹ï¼Œæ ¼å¼ï¼šæ¦‚å¿µ-å…³ç³»->æ¦‚å¿µ
æœ€å¤šè¿”å›5ä¸ªå…³ç³»å¯¹ï¼Œä½¿ç”¨ä¸­æ–‡ã€‚
æ³¨æ„ï¼šå…³ç³»å¯¹å¿…é¡»åŸºäºä¸Šè¿°é—®ç­”å†…å®¹ï¼Œç¡®ä¿å…³ç³»å¯¹ä¸é—®é¢˜å’Œç­”æ¡ˆç´§å¯†ç›¸å…³ã€‚

å…³ç³»å¯¹ç¤ºä¾‹ï¼š
é›„è•Š-ä½äº->æ¤æ ªé¡¶éƒ¨
å»é›„æ“ä½œ-æé«˜->ç‰ç±³äº§é‡
é›„è•Šè¯†åˆ«-éœ€è¦->å›¾åƒæ£€æµ‹

ç›´æ¥è¿”å›å…³ç³»å¯¹ï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šï¼š
"""

        # è®¾ç½®æ›´çŸ­çš„è¶…æ—¶æ—¶é—´
        relationships_result = [None]

        def get_relationships():
            try:
                relationships_result[0] = agriculture_llm.get_expert_answer(kg_prompt, f"é—®é¢˜: {question}")
            except Exception as e:
                relationships_result[0] = f"AIæå–å¤±è´¥: {str(e)}"

        relationships_thread = threading.Thread(target=get_relationships)
        relationships_thread.daemon = True
        relationships_thread.start()
        relationships_thread.join(timeout=8)  # 8ç§’è¶…æ—¶

        if relationships_result[0] is None:
            return generate_fallback_kg(question)

        relationships = relationships_result[0]
        print(f"çŸ¥è¯†å›¾è°±å…³ç³»æå–ç»“æœ: {relationships}")

        # åˆ›å»ºçŸ¥è¯†å›¾è°±
        width, height = 600, 400
        img = Image.new('RGB', (width, height), color='white')
        draw = ImageDraw.Draw(img)

        # åŸºäºé—®é¢˜ç±»å‹é€‰æ‹©é¢„å®šä¹‰çš„å…³ç³»å¯¹ä½œä¸ºå¤‡é€‰
        question_lower = question.lower()

        if any(word in question_lower for word in ['å»é›„', 'å»é™¤', 'æ“ä½œ']):
            predefined_relationships = [
                ("ç‰ç±³é›„è•Š", "ä½äº", "æ¤æ ªé¡¶éƒ¨"),
                ("å»é›„æ“ä½œ", "æé«˜", "ç‰ç±³äº§é‡"),
                ("é›„è•Šè¯†åˆ«", "éœ€è¦", "å›¾åƒæ£€æµ‹"),
                ("æ£€æµ‹æŠ€æœ¯", "è¾…åŠ©", "å†œä¸šç®¡ç†"),
                ("æ“ä½œæ—¶æœº", "å½±å“", "å»é›„æ•ˆæœ")
            ]
        elif any(word in question_lower for word in ['ç—…å®³', 'è™«å®³', 'é˜²æ²»']):
            predefined_relationships = [
                ("ç‰ç±³ç—…å®³", "å½±å“", "é›„è•Šå‘è‚²"),
                ("ç—…å®³é˜²æ²»", "éœ€è¦", "åŠæ—¶è¯†åˆ«"),
                ("ç—…è™«å®³", "å¯¼è‡´", "äº§é‡ä¸‹é™"),
                ("é˜²æ²»æªæ–½", "åŒ…æ‹¬", "å†œè¯ä½¿ç”¨"),
                ("é¢„é˜²æªæ–½", "å‡å°‘", "ç—…å®³å‘ç”Ÿ")
            ]
        else:
            predefined_relationships = [
                ("ç‰ç±³é›„è•Š", "ä½äº", "æ¤æ ªé¡¶éƒ¨"),
                ("å»é›„æ“ä½œ", "æé«˜", "ç‰ç±³äº§é‡"),
                ("é›„è•Šè¯†åˆ«", "éœ€è¦", "å›¾åƒæ£€æµ‹"),
                ("æ£€æµ‹æŠ€æœ¯", "è¾…åŠ©", "å†œä¸šç®¡ç†"),
                ("ç‰ç±³æ¤æ ª", "åŒ…å«", "é›„è•Šé›Œè•Š")
            ]

        nodes = set()
        edges = []

        # è§£æå…³ç³»å¯¹ï¼Œå¦‚æœè§£æå¤±è´¥ä½¿ç”¨é¢„å®šä¹‰çš„
        valid_relationships_found = False
        for line in relationships.split('\n'):
            line = line.strip()
            if '->' in line and '-' in line:
                try:
                    # ç®€å•çš„è§£æé€»è¾‘
                    if ' - ' in line:
                        left, right = line.split(' -> ')
                        if ' - ' in left:
                            source, relation = left.split(' - ')
                            target = right
                            nodes.add(source.strip())
                            nodes.add(target.strip())
                            edges.append((source.strip(), relation.strip(), target.strip()))
                            valid_relationships_found = True
                except:
                    continue

        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå…³ç³»ï¼Œä½¿ç”¨é¢„å®šä¹‰çš„
        if not valid_relationships_found or len(nodes) < 2:
            nodes = set()
            edges = []
            for source, relation, target in predefined_relationships:
                nodes.add(source)
                nodes.add(target)
                edges.append((source, relation, target))

        # é™åˆ¶èŠ‚ç‚¹æ•°é‡ï¼Œæé«˜æ€§èƒ½
        nodes = list(nodes)[:6]  # æœ€å¤š6ä¸ªèŠ‚ç‚¹
        edges = edges[:8]  # æœ€å¤š8æ¡è¾¹

        # è·å–å­—ä½“ - ä¿®å¤å­—ä½“é—®é¢˜
        font, small_font = get_fonts()
        if font is None:
            font = ImageFont.load_default()
        if small_font is None:
            small_font = ImageFont.load_default()

        # ç®€åŒ–çš„ç»˜åˆ¶é€»è¾‘
        center_x, center_y = width // 2, height // 2

        # ç®€å•çš„ç½‘æ ¼å¸ƒå±€è€Œä¸æ˜¯åœ†å½¢å¸ƒå±€
        node_positions = {}
        cols = 3
        node_radius = 40  # ç¨å¾®å¢å¤§èŠ‚ç‚¹åŠå¾„
        spacing_x = width // (cols + 1)
        spacing_y = height // 3

        for i, node in enumerate(nodes):
            row = i // cols
            col = i % cols
            x = spacing_x * (col + 1)
            y = spacing_y * (row + 1)
            node_positions[node] = (x, y)

            # ç®€å•çš„èŠ‚ç‚¹ç»˜åˆ¶
            color = (70, 130, 180) if i % 2 == 0 else (34, 139, 34)
            draw.ellipse([x - node_radius, y - node_radius, x + node_radius, y + node_radius],
                         fill=color, outline='black', width=2)

            # ç®€åŒ–çš„æ–‡å­—ç»˜åˆ¶ - ä½¿ç”¨æ­£ç¡®çš„å­—ä½“
            node_text = node[:4]  # æ˜¾ç¤ºå‰4ä¸ªå­—
            try:
                # è®¡ç®—æ–‡æœ¬å°ºå¯¸
                bbox = draw.textbbox((0, 0), node_text, font=font)
                text_width = bbox[2] - bbox[0]
                text_height = bbox[3] - bbox[1]
                draw.text((x - text_width // 2, y - text_height // 2), node_text, fill='white', font=font)
            except:
                # å¦‚æœå­—ä½“æ¸²æŸ“å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ–‡æœ¬
                text_width = len(node_text) * 10
                draw.text((x - text_width // 2, y - 8), node_text, fill='white')

        # ç®€åŒ–çš„è¾¹ç»˜åˆ¶
        for source, relation, target in edges:
            if source in node_positions and target in node_positions:
                x1, y1 = node_positions[source]
                x2, y2 = node_positions[target]

                # ç®€å•è¿çº¿
                draw.line([x1, y1, x2, y2], fill=(100, 100, 100), width=2)

                # ç®€åŒ–çš„ç®­å¤´
                draw_arrow_simple(draw, x1, y1, x2, y2)

        # ç®€åŒ–çš„æ ‡é¢˜ - ä½¿ç”¨æ­£ç¡®çš„å­—ä½“
        try:
            title_bbox = draw.textbbox((0, 0), "çŸ¥è¯†å›¾è°±", font=font)
            title_width = title_bbox[2] - title_bbox[0]
            draw.text((width // 2 - title_width // 2, 15), "çŸ¥è¯†å›¾è°±", fill=(70, 130, 180), font=font)
        except:
            draw.text((width // 2 - 40, 15), "çŸ¥è¯†å›¾è°±", fill=(70, 130, 180))

        draw.text((20, height - 25), f"æ¦‚å¿µ: {len(nodes)} å…³ç³»: {len(edges)}", fill=(100, 100, 100))

        # ä¼˜åŒ–ä¿å­˜
        output_path = os.path.join(tempfile.gettempdir(), f"kg_{uuid.uuid4().hex}.png")
        img.save(output_path, optimize=True, quality=85)

        filename = os.path.basename(output_path)
        performance_stats["generated_files"].add(filename)

        return output_path, f"âœ… çŸ¥è¯†å›¾è°±ç”Ÿæˆå®Œæˆ ({len(nodes)}ä¸ªæ¦‚å¿µ, {len(edges)}æ¡å…³ç³»)"

    except Exception as e:
        print(f"çŸ¥è¯†å›¾è°±ç”Ÿæˆå¤±è´¥: {e}")
        # è¿”å›ä¸€ä¸ªæç®€çš„å¤‡é€‰å›¾è°±
        return generate_fallback_kg(question)


def generate_fallback_kg(question):
    """ç”Ÿæˆæç®€çš„å¤‡é€‰çŸ¥è¯†å›¾è°± - ä¿®å¤å­—ä½“é—®é¢˜"""
    try:
        width, height = 400, 300
        img = Image.new('RGB', (width, height), color='white')
        draw = ImageDraw.Draw(img)

        # è·å–å­—ä½“
        font, small_font = get_fonts()
        if font is None:
            font = ImageFont.load_default()
        if small_font is None:
            small_font = ImageFont.load_default()

        # æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©ä¸­å¿ƒèŠ‚ç‚¹
        question_lower = question.lower()
        if any(word in question_lower for word in ['å»é›„', 'å»é™¤', 'æ“ä½œ']):
            center_text = "å»é›„"
            concepts = ["é›„è•Š", "æ—¶æœº", "æ–¹æ³•", "æ•ˆæœ"]
        elif any(word in question_lower for word in ['ç—…å®³', 'è™«å®³', 'é˜²æ²»']):
            center_text = "é˜²æ²»"
            concepts = ["ç—…å®³", "è¯†åˆ«", "å†œè¯", "é¢„é˜²"]
        else:
            center_text = "æ ¸å¿ƒ"
            concepts = ["é›„è•Š", "å»é›„", "æ£€æµ‹", "äº§é‡"]

        # ä¸­å¿ƒèŠ‚ç‚¹
        center_x, center_y = width // 2, height // 2
        draw.ellipse([center_x - 40, center_y - 40, center_x + 40, center_y + 40],
                     fill=(70, 130, 180), outline='black', width=2)

        try:
            core_bbox = draw.textbbox((0, 0), center_text, font=font)
            core_width = core_bbox[2] - core_bbox[0]
            core_height = core_bbox[3] - core_bbox[1]
            draw.text((center_x - core_width // 2, center_y - core_height // 2), center_text, fill='white', font=font)
        except:
            draw.text((center_x - 20, center_y - 10), center_text, fill='white')

        # 4ä¸ªæ–¹å‘çš„åŸºç¡€æ¦‚å¿µ
        positions = [
            (center_x, center_y - 80),  # ä¸Š
            (center_x + 80, center_y),  # å³
            (center_x, center_y + 80),  # ä¸‹
            (center_x - 80, center_y)  # å·¦
        ]

        colors = [(34, 139, 34), (46, 139, 87), (139, 69, 19), (72, 61, 139)]

        for i, (concept, pos) in enumerate(zip(concepts, positions)):
            x, y = pos
            draw.ellipse([x - 30, y - 30, x + 30, y + 30],
                         fill=colors[i], outline='black', width=1)

            # ä½¿ç”¨æ­£ç¡®çš„å­—ä½“ç»˜åˆ¶æ–‡å­—
            try:
                concept_bbox = draw.textbbox((0, 0), concept, font=font)
                concept_width = concept_bbox[2] - concept_bbox[0]
                concept_height = concept_bbox[3] - concept_bbox[1]
                draw.text((x - concept_width // 2, y - concept_height // 2), concept, fill='white', font=font)
            except:
                draw.text((x - 10, y - 8), concept, fill='white')

            # è¿çº¿
            draw.line([center_x, center_y, x, y], fill=(100, 100, 100), width=2)
            draw_arrow_simple(draw, center_x, center_y, x, y)

        # æ ‡é¢˜
        try:
            title_bbox = draw.textbbox((0, 0), "çŸ¥è¯†å›¾è°±", font=font)
            title_width = title_bbox[2] - title_bbox[0]
            draw.text((width // 2 - title_width // 2, 10), "çŸ¥è¯†å›¾è°±", fill=(70, 130, 180), font=font)
        except:
            draw.text((width // 2 - 30, 10), "çŸ¥è¯†å›¾è°±", fill=(70, 130, 180))

        draw.text((10, height - 20), "ç®€åŒ–ç‰ˆæœ¬", fill=(150, 150, 150))

        output_path = os.path.join(tempfile.gettempdir(), f"kg_fallback_{uuid.uuid4().hex}.png")
        img.save(output_path, optimize=True)

        filename = os.path.basename(output_path)
        performance_stats["generated_files"].add(filename)

        return output_path, "âœ… åŸºç¡€çŸ¥è¯†å›¾è°±å·²ç”Ÿæˆï¼ˆç®€åŒ–ç‰ˆï¼‰"

    except Exception as e:
        print(f"å¤‡é€‰çŸ¥è¯†å›¾è°±ä¹Ÿå¤±è´¥: {e}")
        return None, f"çŸ¥è¯†å›¾è°±ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"


# ä¿®æ”¹é—®ç­”å¤„ç†å‡½æ•°ï¼Œä¿®å¤è¯­éŸ³ç”Ÿæˆé—®é¢˜
def handle_question_with_context(question, enable_voice_answer, generate_kg):
    """å¤„ç†æ–‡æœ¬æé—® - ç»“åˆæ£€æµ‹ä¸Šä¸‹æ–‡ï¼Œä¿®å¤è¯­éŸ³åˆæˆ"""
    if not question.strip():
        return "è¯·å…ˆè¾“å…¥æ‚¨å…³äºç‰ç±³å»é›„çš„é—®é¢˜", None, "è¯·å…ˆæé—®å¹¶è·å¾—ç­”æ¡ˆ"

    try:
        # è·å–æ£€æµ‹ä¸Šä¸‹æ–‡
        detection_context = get_detection_context()
        print(f"æ£€æµ‹ä¸Šä¸‹æ–‡: {detection_context}")

        # æ„å»ºæ™ºèƒ½æç¤ºè¯ï¼Œç»“åˆæ£€æµ‹æ•°æ®
        enhanced_prompt = f"""
        ç”¨æˆ·æé—®ï¼š{question}

        å½“å‰æ£€æµ‹æ•°æ®ï¼š{detection_context}

        è¯·ç›´æ¥ã€ä¸“ä¸šåœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œè¦æ±‚ï¼š
        - ç«‹å³ç»™å‡ºç­”æ¡ˆï¼Œä¸è¦æœ‰ä»»ä½•æ€è€ƒè¿‡ç¨‹ã€åˆ†ææ­¥éª¤æˆ–å†…éƒ¨æ¨ç†
        - åŸºäºæ£€æµ‹æ•°æ®æä¾›å…·ä½“ä¿¡æ¯
        - å›ç­”è¦è¯¦ç»†ä½†ç›´æ¥ç›¸å…³ï¼Œé¿å…æ— å…³è§£é‡Š
        - ä½¿ç”¨æ¸…æ™°çš„ä¸“ä¸šè¯­è¨€
        - å¦‚æœæ¶‰åŠæ“ä½œï¼Œç›´æ¥ç»™å‡ºæ­¥éª¤ï¼Œä¸è¦è§£é‡Šä¸ºä»€ä¹ˆ

        ç›´æ¥å›ç­”ï¼š
        """

        # ä½¿ç”¨å¢å¼ºçš„æç¤ºè¯è·å–å›ç­”
        answer_response = agriculture_llm.get_expert_answer(enhanced_prompt, question)
        # æ¸…ç†å“åº”ï¼Œå»é™¤æ€è€ƒè¿‡ç¨‹
        answer = clean_ai_response(answer_response)

        print(f"âœ… AIå›ç­”ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(answer)}")

        # è¯­éŸ³å›ç­” - ä½¿ç”¨é”é¿å…å¹¶å‘é—®é¢˜
        audio_file = None
        if enable_voice_answer and answer:
            print("ğŸ”Š å¼€å§‹è¯­éŸ³åˆæˆ...")
            try:
                speech_processor = get_speech_processor()
                if speech_processor and hasattr(speech_processor, 'tts_engine') and speech_processor.tts_engine:
                    # ä½¿ç”¨é”ç¡®ä¿åŒä¸€æ—¶é—´åªæœ‰ä¸€ä¸ªè¯­éŸ³ç”Ÿæˆä»»åŠ¡
                    with voice_lock:
                        audio_result = [None]

                        # åœ¨ handle_question_with_context å’Œ handle_voice_question_with_context ä¸­
                        # ä¿®æ”¹è¯­éŸ³åˆæˆéƒ¨åˆ†ï¼š

                        def generate_audio():
                            try:
                                speech_processor = get_speech_processor()
                                # ä½¿ç”¨ä¿®å¤åçš„ text_to_speech æ–¹æ³•
                                audio_file_path = speech_processor.text_to_speech(answer, save_to_file=True)
                                if audio_file_path and os.path.exists(audio_file_path):
                                    filename = os.path.basename(audio_file_path)
                                    performance_stats["generated_files"].add(filename)
                                    audio_result[0] = audio_file_path
                                    print(f"âœ… è¯­éŸ³æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {audio_file_path}")
                                else:
                                    print("âŒ è¯­éŸ³æ–‡ä»¶ç”Ÿæˆå¤±è´¥")
                            except Exception as e:
                                print(f"âŒ è¯­éŸ³ç”Ÿæˆçº¿ç¨‹å¼‚å¸¸: {e}")

                        audio_thread = threading.Thread(target=generate_audio)
                        audio_thread.daemon = True
                        audio_thread.start()
                        audio_thread.join(timeout=15)

                        audio_file = audio_result[0]

                    if not audio_file:
                        print("âš ï¸ è¯­éŸ³ç”Ÿæˆè¶…æ—¶æˆ–å¤±è´¥")
                else:
                    print("âŒ è¯­éŸ³åˆæˆå¼•æ“ä¸å¯ç”¨")
            except Exception as e:
                print(f"âŒ è¯­éŸ³åˆæˆå¤„ç†å¤±è´¥: {e}")
        else:
            print("ğŸ”‡ è¯­éŸ³å›ç­”æœªå¯ç”¨")

        # çŸ¥è¯†å›¾è°±ç”Ÿæˆ - ä¿®æ”¹ä¸ºä¿å­˜åˆ°å†å²è®°å½•
        kg_status = ""
        if generate_kg and answer:
            try:
                kg_image, kg_status = generate_knowledge_graph_optimized(question, answer)
                if kg_image:
                    # ä¿å­˜åˆ°çŸ¥è¯†å›¾è°±å†å²è®°å½•
                    save_knowledge_graph_record(question, answer, kg_image)
                    kg_status = "âœ… çŸ¥è¯†å›¾è°±å·²ç”Ÿæˆå¹¶ä¿å­˜åˆ°çŸ¥è¯†å›¾è°±åº“"
                else:
                    kg_status = "âŒ çŸ¥è¯†å›¾è°±ç”Ÿæˆå¤±è´¥"
            except Exception as e:
                print(f"çŸ¥è¯†å›¾è°±ç”Ÿæˆå¤±è´¥: {e}")
                kg_status = "çŸ¥è¯†å›¾è°±ç”Ÿæˆå¤±è´¥"
        else:
            kg_status = "æœªå¯ç”¨çŸ¥è¯†å›¾è°±ç”Ÿæˆ"

        # è§¦å‘æ¸…ç†
        cleanup_old_files()

        return answer, audio_file, kg_status  # è¿”å›Noneç»™kg_imageï¼Œå› ä¸ºä¸åœ¨å½“å‰ç•Œé¢æ˜¾ç¤º

    except Exception as e:
        print(f"é—®ç­”å¤„ç†å¤±è´¥: {e}")
        error_msg = f"AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚é”™è¯¯: {str(e)}"
        return error_msg, None, "çŸ¥è¯†å›¾è°±ç”Ÿæˆå¤±è´¥"



def generate_comprehensive_report(area_info="", date_range="å…¨éƒ¨æ•°æ®"):
    """ç”Ÿæˆç»¼åˆå·¥ä½œæŠ¥å‘Š - ä¼˜åŒ–æ€§èƒ½"""
    if not detection_history:
        return "æš‚æ— æ£€æµ‹æ•°æ®ï¼Œè¯·å…ˆè¿›è¡Œæ£€æµ‹æ“ä½œ", None

    try:
        # ç­›é€‰æ•°æ®
        relevant_data = [
            record for record in detection_history
            if not area_info or area_info in record.get('area', '')
        ]

        if not relevant_data:
            return f"åŒºåŸŸ '{area_info}' æš‚æ— æ£€æµ‹æ•°æ®", None

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        total_detections = len(relevant_data)
        total_stamens = sum(record['data'].get('total_count', 0) for record in relevant_data)
        avg_stamens = total_stamens / total_detections if total_detections > 0 else 0

        # æŒ‰åŒºåŸŸç»Ÿè®¡
        area_stats = {}
        for record in relevant_data:
            area = record.get('area', 'æœªåˆ†ç±»')
            if area not in area_stats:
                area_stats[area] = {'count': 0, 'stamens': 0}
            area_stats[area]['count'] += 1
            area_stats[area]['stamens'] += record['data'].get('total_count', 0)

        # ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        stats_text = f"""
## ğŸ“Š ç»¼åˆæ£€æµ‹æŠ¥å‘Š

### æ€»ä½“ç»Ÿè®¡
- **æ€»æ£€æµ‹æ¬¡æ•°**: {total_detections} æ¬¡
- **æ€»é›„è•Šæ•°é‡**: {total_stamens} ä¸ª
- **å¹³å‡æ¯å¼ å›¾åƒ**: {avg_stamens:.1f} ä¸ªé›„è•Š
- **æ—¶é—´èŒƒå›´**: {date_range}
- **åŒºåŸŸç­›é€‰**: {area_info if area_info else "å…¨éƒ¨åŒºåŸŸ"}

### åŒºåŸŸç»Ÿè®¡
"""
        for area, stats in area_stats.items():
            stats_text += f"- **{area}**: {stats['count']} æ¬¡æ£€æµ‹ï¼Œ{stats['stamens']} ä¸ªé›„è•Š\n"

        # ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½åˆ†ææŠ¥å‘Š - ä½¿ç”¨çº¿ç¨‹é¿å…é˜»å¡
        analysis_report = ""

        def generate_analysis_thread():
            nonlocal analysis_report
            try:
                analysis_prompt = f"""
åŸºäºä»¥ä¸‹ç‰ç±³å»é›„æ£€æµ‹æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ç»¼åˆåˆ†ææŠ¥å‘Šï¼š

**æ•°æ®æ¦‚å†µ**ï¼š
- æ€»æ£€æµ‹æ¬¡æ•°: {total_detections}
- æ€»é›„è•Šæ•°é‡: {total_stamens}
- å¹³å‡æ¯å¼ å›¾åƒé›„è•Šæ•°: {avg_stamens:.1f}
- åŒºåŸŸåˆ†å¸ƒ: {list(area_stats.keys())}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
1. å·¥ä½œå®Œæˆæƒ…å†µè¯„ä¼°
2. é›„è•Šåˆ†å¸ƒç‰¹ç‚¹åˆ†æ  
3. å¯èƒ½å­˜åœ¨çš„é—®é¢˜å’Œæ”¹è¿›å»ºè®®
4. ä¸‹ä¸€æ­¥å·¥ä½œè®¡åˆ’

è¦æ±‚ï¼š
- ç›´æ¥ç»™å‡ºåˆ†æç»“æœï¼Œä¸è¦æœ‰ä»»ä½•æ€è€ƒè¿‡ç¨‹æˆ–è§£é‡Š
- åˆ†ç‚¹åˆ—å‡ºï¼Œæ¸…æ™°æ˜äº†
- åŸºäºæ•°æ®ç»™å‡ºå…·ä½“å»ºè®®
- ä½¿ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€

ç›´æ¥ç»™å‡ºåˆ†ææŠ¥å‘Šï¼š
"""
                analysis_response = agriculture_llm.get_expert_answer(analysis_prompt, f"æ£€æµ‹æ¬¡æ•°: {total_detections}")
                analysis_report = clean_ai_response(analysis_response)
            except Exception as e:
                print(f"ç”Ÿæˆåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
                analysis_report = "ä¸“ä¸šåˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

        # å¯åŠ¨åˆ†æçº¿ç¨‹
        analysis_thread = threading.Thread(target=generate_analysis_thread)
        analysis_thread.daemon = True
        analysis_thread.start()
        analysis_thread.join(timeout=15)  # 15ç§’è¶…æ—¶

        if analysis_thread.is_alive():
            analysis_report = "ä¸“ä¸šåˆ†æç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"

        full_report = stats_text + f"\n### ğŸ“‹ ä¸“ä¸šåˆ†æ\n{analysis_report}"

        # ç”ŸæˆPDFæŠ¥å‘Š - ä½¿ç”¨çº¿ç¨‹é¿å…é˜»å¡
        pdf_path = None

        def generate_pdf_thread():
            nonlocal pdf_path
            try:
                pdf_path = generate_pdf_report(full_report, area_info, date_range, total_detections, total_stamens, area_stats, analysis_report)
            except Exception as e:
                print(f"ç”ŸæˆPDFå¤±è´¥: {e}")

        pdf_thread = threading.Thread(target=generate_pdf_thread)
        pdf_thread.daemon = True
        pdf_thread.start()
        pdf_thread.join(timeout=10)  # 10ç§’è¶…æ—¶

        # è§¦å‘æ¸…ç†
        cleanup_old_files()

        return full_report, pdf_path

    except Exception as e:
        return f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}", None

def generate_pdf_report(report_content, area_info, date_range, total_detections, total_stamens, area_stats, analysis_report):
    """ç”ŸæˆPDFæ ¼å¼çš„æŠ¥å‘Š - ä¼˜åŒ–æ€§èƒ½"""
    try:
        pdf_path = os.path.join(tempfile.gettempdir(), f"corn_detection_report_{uuid.uuid4().hex}.pdf")

        # æ–¹æ³•1ï¼šä½¿ç”¨reportlabï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            from reportlab.lib.pagesizes import letter, A4
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch
            from reportlab.lib import colors
            from reportlab.pdfbase import pdfmetrics
            from reportlab.pdfbase.ttfonts import TTFont

            # å°è¯•æ³¨å†Œä¸­æ–‡å­—ä½“
            try:
                font_paths = [
                    "C:/Windows/Fonts/simsun.ttc",  # Windows å®‹ä½“
                    "C:/Windows/Fonts/simhei.ttf",  # Windows é»‘ä½“
                    "/System/Library/Fonts/PingFang.ttc",  # macOS
                    "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf",  # Linux
                ]

                chinese_font = None
                for font_path in font_paths:
                    if os.path.exists(font_path):
                        try:
                            font_name = os.path.basename(font_path).split('.')[0]
                            pdfmetrics.registerFont(TTFont(font_name, font_path))
                            chinese_font = font_name
                            break
                        except:
                            continue

                if not chinese_font:
                    chinese_font = "Helvetica"
            except:
                chinese_font = "Helvetica"

            doc = SimpleDocTemplate(pdf_path, pagesize=A4)

            styles = getSampleStyleSheet()
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Heading1'],
                fontName=chinese_font,
                fontSize=16,
                spaceAfter=30,
                alignment=1
            )
            heading_style = ParagraphStyle(
                'CustomHeading',
                parent=styles['Heading2'],
                fontName=chinese_font,
                fontSize=14
            )
            normal_style = ParagraphStyle(
                'CustomNormal',
                parent=styles['Normal'],
                fontName=chinese_font,
                fontSize=10
            )

            story = []

            title = Paragraph("ç‰ç±³å»é›„æ£€æµ‹å·¥ä½œæŠ¥å‘Š", title_style)
            story.append(title)
            story.append(Spacer(1, 0.2 * inch))

            info_text = f"<b>ç”Ÿæˆæ—¶é—´:</b> {datetime.now().strftime('%Y-%m-%d %H:%M')}<br/>"
            info_text += f"<b>åŒºåŸŸç­›é€‰:</b> {area_info if area_info else 'å…¨éƒ¨åŒºåŸŸ'}<br/>"
            info_text += f"<b>æ—¶é—´èŒƒå›´:</b> {date_range}<br/>"
            info_text += f"<b>æ€»æ£€æµ‹æ¬¡æ•°:</b> {total_detections}<br/>"
            info_text += f"<b>æ€»é›„è•Šæ•°é‡:</b> {total_stamens}<br/>"

            info_para = Paragraph(info_text, normal_style)
            story.append(info_para)
            story.append(Spacer(1, 0.3 * inch))

            if area_stats:
                area_data = [['åŒºåŸŸ', 'æ£€æµ‹æ¬¡æ•°', 'é›„è•Šæ•°é‡']]
                for area, stats in area_stats.items():
                    area_data.append([area, str(stats['count']), str(stats['stamens'])])

                table = Table(area_data, colWidths=[2 * inch, 1.5 * inch, 1.5 * inch])
                table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('FONTNAME', (0, 0), (-1, 0), chinese_font),
                    ('FONTSIZE', (0, 0), (-1, 0), 12),
                    ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                    ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                    ('FONTNAME', (0, 1), (-1, -1), chinese_font),
                    ('GRID', (0, 0), (-1, -1), 1, colors.black)
                ]))
                story.append(table)
                story.append(Spacer(1, 0.3 * inch))

            if analysis_report:
                clean_analysis = analysis_report.replace('**', '').replace('###', '').strip()
                analysis_para = Paragraph(f"<b>ä¸“ä¸šåˆ†æ</b><br/>{clean_analysis}", normal_style)
                story.append(analysis_para)

            doc.build(story)

            filename = os.path.basename(pdf_path)
            performance_stats["generated_files"].add(filename)

            return pdf_path

        except ImportError:
            print("âš ï¸ reportlabä¸å¯ç”¨ï¼Œç”Ÿæˆæ–‡æœ¬æ ¼å¼æŠ¥å‘Š")
            txt_path = os.path.join(tempfile.gettempdir(), f"corn_detection_report_{uuid.uuid4().hex}.txt")
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write("ç‰ç±³å»é›„æ£€æµ‹å·¥ä½œæŠ¥å‘Š\n")
                f.write("=" * 50 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
                f.write(f"åŒºåŸŸç­›é€‰: {area_info if area_info else 'å…¨éƒ¨åŒºåŸŸ'}\n")
                f.write(f"æ—¶é—´èŒƒå›´: {date_range}\n")
                f.write(f"æ€»æ£€æµ‹æ¬¡æ•°: {total_detections}\n")
                f.write(f"æ€»é›„è•Šæ•°é‡: {total_stamens}\n\n")

                if area_stats:
                    f.write("åŒºåŸŸç»Ÿè®¡:\n")
                    for area, stats in area_stats.items():
                        f.write(f"  {area}: {stats['count']}æ¬¡æ£€æµ‹, {stats['stamens']}ä¸ªé›„è•Š\n")
                    f.write("\n")

                if analysis_report:
                    f.write("ä¸“ä¸šåˆ†æ:\n")
                    clean_analysis = analysis_report.replace('**', '').replace('###', '').strip()
                    f.write(clean_analysis + "\n")

            filename = os.path.basename(txt_path)
            performance_stats["generated_files"].add(filename)

            return txt_path

    except Exception as e:
        print(f"ç”ŸæˆPDFå¤±è´¥: {e}")
        return None


def fast_inference_with_brightness(img, threshold, brightness_factor, area_info, enable_guidance):
    """å¸¦äº®åº¦è°ƒèŠ‚çš„å¿«é€Ÿæ£€æµ‹æ¨ç†å‡½æ•°"""
    processed_img = preprocess_image(img)
    if processed_img is None:
        return None, "è¯·å…ˆä¸Šä¼ æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶", "", None

    try:
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = datetime.now()

        # æ‰§è¡Œå¸¦äº®åº¦è°ƒèŠ‚çš„æ£€æµ‹
        from Stamen_detection import detect_stamen_with_brightness
        boxed_pil, detection_result, histogram_img = detect_stamen_with_brightness(
            processed_img, threshold, brightness_factor
        )

        # è®¡ç®—å¤„ç†æ—¶é—´
        process_time = (datetime.now() - start_time).total_seconds()

        # ç”Ÿæˆæ£€æµ‹ç»“æœæ–‡æœ¬
        detection_text = detection_result.to_text_summary()

        # æ·»åŠ ä½ç½®ä¿¡æ¯
        if hasattr(detection_result, 'to_position_summary'):
            position_text = detection_result.to_position_summary()
            full_detection_text = f"{detection_text}\n\n{position_text}"
        else:
            full_detection_text = detection_text

        # æ·»åŠ å¤„ç†æ—¶é—´ä¿¡æ¯
        full_detection_text = f"â±ï¸ å¤„ç†æ—¶é—´: {process_time:.2f}ç§’\näº®åº¦è°ƒèŠ‚: {brightness_factor}x\n\n{full_detection_text}"

        # ä¿å­˜æ£€æµ‹è®°å½•
        detection_data = detection_result.get_detection_data()
        save_detection_record(detection_data, area_info)

        # ä¿å­˜äº®åº¦ç›´æ–¹å›¾
        histogram_path = None
        if histogram_img:
            histogram_path = os.path.join(tempfile.gettempdir(), f"histogram_{uuid.uuid4().hex}.png")
            histogram_img.save(histogram_path)
            performance_stats["generated_files"].add(os.path.basename(histogram_path))

        # ç”Ÿæˆæ“ä½œæŒ‡å¯¼
        guidance_text = ""
        if enable_guidance and detection_result.detected_objects:
            try:
                guidance_prompt = f"""
æ£€æµ‹ç»“æœï¼š{detection_text}
äº®åº¦è°ƒèŠ‚ï¼š{brightness_factor}x

è¯·ç›´æ¥ç»™å‡ºå…·ä½“çš„å»é›„æ“ä½œæŒ‡å¯¼ï¼Œè¦æ±‚ï¼š
- ç›´æ¥ç»™å‡ºæ“ä½œæ­¥éª¤ï¼Œä¸è¦æœ‰ä»»ä½•æ€è€ƒè¿‡ç¨‹
- æ­¥éª¤æ¸…æ™°å®ç”¨ï¼Œæ˜“äºæ‰§è¡Œ
- åŸºäºæ£€æµ‹ç»“æœé’ˆå¯¹æ€§å»ºè®®
- ä½¿ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€
- ä¸è¶…è¿‡5ä¸ªæ­¥éª¤

æ“ä½œæŒ‡å¯¼ï¼š
"""
                guidance_response = agriculture_llm.get_expert_answer(guidance_prompt, detection_text)
                guidance_text = clean_ai_response(guidance_response)
            except Exception as e:
                print(f"ç”ŸæˆæŒ‡å¯¼å¤±è´¥: {e}")
                guidance_text = "AIæŒ‡å¯¼æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·å‚è€ƒæ ‡å‡†æ“ä½œæµç¨‹ã€‚"

        # ä¿å­˜ç»“æœå›¾åƒ
        out_path = os.path.join(tempfile.gettempdir(), f"{uuid.uuid4().hex}.jpg")
        out_path = safe_image_save(boxed_pil, out_path, quality=85)

        print(
            f"å¸¦äº®åº¦è°ƒèŠ‚æ£€æµ‹å®Œæˆï¼Œäº®åº¦: {brightness_factor}xï¼Œå‘ç° {len(detection_result.detected_objects)} ä¸ªé›„è•Šï¼Œè€—æ—¶ {process_time:.2f}ç§’")

        # è°ƒè¯•ä¿¡æ¯
        if detection_result.detected_objects:
            for i, obj in enumerate(detection_result.detected_objects):
                print(f"æ£€æµ‹å¯¹è±¡ {i}: æ ‡ç­¾={obj['label']}, ç½®ä¿¡åº¦={obj['confidence']:.2f}, ä½ç½®={obj['position']}")

        return out_path, full_detection_text, guidance_text, histogram_path

    except Exception as e:
        error_msg = f"æ£€æµ‹å¤±è´¥: {str(e)}"
        print(f"é”™è¯¯è¯¦æƒ…: {e}")
        import traceback
        traceback.print_exc()  # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆ
        return None, error_msg, "", None


def clear_history():
    """æ¸…ç©ºæ£€æµ‹å†å²"""
    global detection_history
    detection_history = []

    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    gc.collect()

    return "æ£€æµ‹å†å²å·²æ¸…ç©º", None


# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(
        title=TITLE,
        theme=gr.themes.Soft(
            primary_hue="gray",
            secondary_hue="gray",
            neutral_hue="gray"
        ),
        css="""
    .main-container {
        max-width: 1400px;
        margin: 0 auto;
        padding: 20px;
    }
    .header-section {
        text-align: center;
        margin-bottom: 30px;
        padding: 25px;
        background: white;
        border-radius: 8px;
        border: 2px solid #000;
        color: #000;
    }
    .tab-content {
        padding: 20px;
        background: white;
        border-radius: 8px;
        border: 1px solid #000;
        margin-bottom: 20px;
    }
    .input-section {
        background: white;
        padding: 20px;
        border-radius: 8px;
        border: 1px solid #000;
    }
    .result-section {
        background: white;
        padding: 20px;
        border-radius: 8px;
        border: 1px solid #000;
    }
    .stats-card {
        background: white;
        color: #000;
        padding: 15px;
        border-radius: 6px;
        margin: 10px 0;
        border: 1px solid #000;
    }
    .voice-card {
        background: white;
        color: #000;
        padding: 15px;
        border-radius: 6px;
        margin: 10px 0;
        border: 1px solid #000;
    }
    .detection-card {
        background: white;
        color: #000;
        padding: 15px;
        border-radius: 6px;
        margin: 10px 0;
        border: 1px solid #000;
    }
    .btn-primary {
        background: #000;
        border: 1px solid #000;
        color: white;
        font-weight: 500;
    }
    .btn-primary:hover {
        background: #333;
        border: 1px solid #333;
    }
    .btn-secondary {
        background: #666;
        border: 1px solid #666;
        color: white;
        font-weight: 500;
    }
    .btn-secondary:hover {
        background: #888;
        border: 1px solid #888;
    }
    .gradio-image {
        border-radius: 6px;
        border: 1px solid #000;
    }
    .gradio-textbox textarea {
        border-radius: 6px;
        border: 1px solid #000;
        background: white;
    }
    .gradio-slider {
        background: white;
    }
    .accordion-header {
        background: #f5f5f5 !important;
        border: 1px solid #000 !important;
    }
    .knowledge-graph-card {
        background: white;
        color: #000;
        padding: 15px;
        border-radius: 6px;
        margin: 10px 0;
        border: 1px solid #000;
    }
    .pdf-download-card {
        background: white;
        color: #000;
        padding: 15px;
        border-radius: 6px;
        margin: 10px 0;
        border: 1px solid #000;
    }
    .kg-gallery-card {
        background: white;
        color: #000;
        padding: 15px;
        border-radius: 6px;
        margin: 10px 0;
        border: 1px solid #000;
    }
    """) as demo:
    # å¤´éƒ¨åŒºåŸŸ
    with gr.Column(elem_classes=["header-section"]):
        gr.Markdown(f"# {TITLE}")
        gr.Markdown(f"### {DESCRIPTION}")

    with gr.Column(elem_classes=["main-container"]):
        with gr.Tab("ğŸ” å›¾åƒæ£€æµ‹"):
            # ... å›¾åƒæ£€æµ‹Tabå†…å®¹ä¿æŒä¸å˜ ...
            with gr.Row(equal_height=False):
                with gr.Column(scale=1):
                    with gr.Group(elem_classes=["input-section"]):
                        gr.Markdown("### ğŸ“¸ å›¾åƒè¾“å…¥")
                        in_img = gr.Image(
                            label="ä¸Šä¼ ç‰ç±³æ¤æ ªå›¾åƒ",
                            type="filepath",
                            sources=["upload", "webcam"],
                            height=280
                        )

                        with gr.Row():
                            threshold = gr.Slider(
                                0.1, 0.95, 0.5, step=0.05,
                                label="æ£€æµ‹çµæ•åº¦",
                                info="å€¼è¶Šé«˜ï¼Œæ£€æµ‹è¶Šä¸¥æ ¼"
                            )

                        with gr.Row():
                            brightness_slider = gr.Slider(
                                0.1, 3.0, 1.0, step=0.1,
                                label="å›¾åƒäº®åº¦è°ƒèŠ‚",
                                info="1.0ä¸ºåŸå§‹äº®åº¦ï¼Œå°äº1è°ƒæš—ï¼Œå¤§äº1è°ƒäº®"
                            )

                        with gr.Row():
                            area_info = gr.Textbox(
                                label="å·¥ä½œåŒºåŸŸ",
                                placeholder="ä¾‹å¦‚ï¼šA01",
                                max_lines=1
                            )

                        with gr.Row():
                            enable_guidance = gr.Checkbox(
                                label="å¯ç”¨AIæ“ä½œæŒ‡å¯¼",
                                value=True
                            )

                            btn_detect = gr.Button(
                                "å¼€å§‹æ£€æµ‹",
                                variant="primary",
                                size="lg"
                            )

                with gr.Column(scale=1):
                    with gr.Group(elem_classes=["result-section"]):
                        gr.Markdown("### ğŸ“Š æ£€æµ‹ç»“æœ")

                        with gr.Accordion("ğŸ“ˆ å›¾åƒäº®åº¦åˆ†æ", open=True):
                            brightness_histogram = gr.Image(
                                label="äº®åº¦åˆ†å¸ƒç›´æ–¹å›¾",
                                type="filepath",
                                height=200,
                                show_download_button=True
                            )

                        out_img = gr.Image(
                            label="æ£€æµ‹ç»“æœ",
                            type="filepath",
                            height=300,
                            show_download_button=True
                        )

                        with gr.Group(elem_classes=["stats-card"]):
                            stats_display = gr.Textbox(
                                label="å®æ—¶ç»Ÿè®¡",
                                value="ç­‰å¾…æ£€æµ‹...",
                                lines=2,
                                interactive=False
                            )

                        with gr.Accordion("æ£€æµ‹è¯¦æƒ…", open=True):
                            out_detection = gr.Textbox(
                                label="",
                                lines=4,
                                show_copy_button=True
                            )

                        with gr.Accordion("æ“ä½œæŒ‡å¯¼", open=True):
                            out_guidance = gr.Textbox(
                                label="",
                                lines=3,
                                show_copy_button=True
                            )

        with gr.Tab("ğŸ’¬ æ™ºèƒ½é—®ç­”"):
            # ä¿®æ”¹æ™ºèƒ½é—®ç­”ç•Œé¢ï¼Œç§»é™¤çŸ¥è¯†å›¾è°±æ˜¾ç¤ºåŒºåŸŸ
            with gr.Row():
                with gr.Column(scale=1):
                    with gr.Group(elem_classes=["input-section"]):
                        gr.Markdown("### ğŸ¤ è¯­éŸ³æé—®")

                        with gr.Group(elem_classes=["stats-card"]):
                            detection_status = gr.Textbox(
                                label="æ£€æµ‹æ•°æ®çŠ¶æ€",
                                value="ç­‰å¾…æ£€æµ‹æ•°æ®...",
                                lines=2,
                                interactive=False
                            )
                            btn_refresh_status = gr.Button("åˆ·æ–°æ£€æµ‹çŠ¶æ€", variant="secondary", size="sm")

                        with gr.Group(elem_classes=["voice-card"]):
                            voice_input = gr.Audio(
                                label="å½•åˆ¶è¯­éŸ³é—®é¢˜",
                                sources=["microphone"],
                                type="filepath"
                            )
                            btn_voice_question = gr.Button("è¯†åˆ«è¯­éŸ³å¹¶æé—®", variant="primary")

                        gr.Markdown("### ğŸ“ æ–‡æœ¬æé—®")

                        preset_questions = [
                            "å½“å‰é›„è•Šæ•°é‡å¤šå°‘ï¼Ÿ",
                            "é›„è•Šåˆ†å¸ƒä½ç½®å¦‚ä½•ï¼Ÿ",
                            "æ£€æµ‹ç»“æœå¯ä¿¡å—ï¼Ÿ",
                            "æ¥ä¸‹æ¥è¯¥åšä»€ä¹ˆæ“ä½œï¼Ÿ",
                            "å¦‚ä½•æé«˜æ£€æµ‹å‡†ç¡®æ€§ï¼Ÿ",
                            "é›„è•Šæ•°é‡æ­£å¸¸å—ï¼Ÿ",
                            "éœ€è¦å»é›„æ“ä½œå—ï¼Ÿ",
                            "æ£€æµ‹åˆ°çš„é›„è•Šè´¨é‡å¦‚ä½•ï¼Ÿ"
                        ]

                        with gr.Accordion("ğŸ’¡ å¸¸ç”¨é—®é¢˜ç¤ºä¾‹", open=False):
                            gr.Markdown("ç‚¹å‡»ä»¥ä¸‹é—®é¢˜å¿«é€Ÿæé—®ï¼š")
                            with gr.Row():
                                preset_buttons = []
                                for i, question in enumerate(preset_questions[:4]):
                                    btn = gr.Button(question, size="sm")
                                    preset_buttons.append(btn)
                            with gr.Row():
                                for i, question in enumerate(preset_questions[4:]):
                                    btn = gr.Button(question, size="sm")
                                    preset_buttons.append(btn)

                        question_input = gr.Textbox(
                            label="è¾“å…¥é—®é¢˜",
                            placeholder="ä¾‹å¦‚ï¼šå½“å‰é›„è•Šæ•°é‡å¤šå°‘ï¼Ÿå¦‚ä½•é˜²æ²»ç—…è™«å®³ï¼Ÿé›„è•Šä½ç½®åˆ†å¸ƒå¦‚ä½•ï¼Ÿ",
                            lines=3
                        )

                        with gr.Row():
                            enable_voice_answer = gr.Checkbox(
                                label="å¯ç”¨è¯­éŸ³å›ç­”",
                                value=True
                            )
                            generate_kg = gr.Checkbox(
                                label="ç”ŸæˆçŸ¥è¯†å›¾è°±",
                                value=True,
                                info="å›¾è°±å°†ä¿å­˜åˆ°çŸ¥è¯†å›¾è°±åº“"
                            )

                        btn_question = gr.Button("å‘é€é—®é¢˜", variant="primary", size="lg")

                        voice_question_text = gr.Textbox(
                            label="è¯­éŸ³è¯†åˆ«ç»“æœ",
                            lines=2,
                            interactive=False,
                            show_copy_button=True
                        )

                with gr.Column(scale=2):
                    with gr.Group(elem_classes=["result-section"]):
                        # ç§»é™¤çŸ¥è¯†å›¾è°±æ˜¾ç¤ºåŒºåŸŸï¼Œåªæ˜¾ç¤ºä¸“å®¶è§£ç­”
                        gr.Markdown("### ğŸ’¡ ä¸“å®¶è§£ç­”")
                        answer_output = gr.Textbox(
                            label="AIå›ç­”",
                            lines=12,
                            show_copy_button=True
                        )

                        voice_answer_audio = gr.Audio(
                            label="è¯­éŸ³å›ç­”",
                            type="filepath",
                            show_download_button=True
                        )

                        # åªæ˜¾ç¤ºçŸ¥è¯†å›¾è°±ç”ŸæˆçŠ¶æ€
                        kg_status = gr.Textbox(
                            label="çŸ¥è¯†å›¾è°±çŠ¶æ€",
                            lines=2,
                            interactive=False
                        )

        with gr.Tab("ğŸ§  çŸ¥è¯†å›¾è°±åº“"):
            with gr.Row():
                with gr.Column(scale=2):
                    with gr.Group(elem_classes=["kg-gallery-card"]):
                        gr.Markdown("### ğŸ“š çŸ¥è¯†å›¾è°±ç”»å»Š")
                        kg_gallery = gr.Gallery(
                            label="å†å²çŸ¥è¯†å›¾è°±",
                            columns=4,
                            rows=2,
                            height=400,
                            object_fit="contain",
                            show_label=False
                        )
                        gallery_status = gr.Textbox(
                            label="ç”»å»ŠçŠ¶æ€",
                            lines=1,
                            interactive=False
                        )

                        with gr.Row():
                            btn_refresh_gallery = gr.Button("åˆ·æ–°ç”»å»Š", variant="secondary")
                            btn_clear_kg_history = gr.Button("æ¸…ç©ºå†å²", variant="secondary")

                with gr.Column(scale=1):
                    with gr.Group(elem_classes=["result-section"]):
                        gr.Markdown("### ğŸ” å›¾è°±è¯¦æƒ…")
                        selected_kg_image = gr.Image(
                            label="é€‰ä¸­çš„çŸ¥è¯†å›¾è°±",
                            type="filepath",
                            height=300,
                            show_download_button=True
                        )

                        selected_question = gr.Textbox(
                            label="é—®é¢˜",
                            lines=2,
                            interactive=False
                        )

                        selected_answer = gr.Textbox(
                            label="ç­”æ¡ˆæ‘˜è¦",
                            lines=4,
                            interactive=False
                        )

                        selected_timestamp = gr.Textbox(
                            label="ç”Ÿæˆæ—¶é—´",
                            lines=1,
                            interactive=False
                        )

        with gr.Tab("ğŸ“ˆ å·¥ä½œæŠ¥å‘Š"):
            # ... å·¥ä½œæŠ¥å‘ŠTabå†…å®¹ä¿æŒä¸å˜ ...
            with gr.Row():
                with gr.Column(scale=1):
                    with gr.Group(elem_classes=["input-section"]):
                        gr.Markdown("### ğŸ“‹ æŠ¥å‘Šè®¾ç½®")
                        report_area = gr.Textbox(
                            label="åŒºåŸŸç­›é€‰",
                            placeholder="ç•™ç©ºåˆ™ç»Ÿè®¡æ‰€æœ‰åŒºåŸŸ"
                        )
                        date_filter = gr.Dropdown(
                            choices=["ä»Šæ—¥", "æœ€è¿‘3å¤©", "æœ€è¿‘7å¤©", "å…¨éƒ¨æ•°æ®"],
                            label="æ—¶é—´èŒƒå›´",
                            value="å…¨éƒ¨æ•°æ®"
                        )
                        with gr.Row():
                            btn_report = gr.Button("ç”Ÿæˆç»¼åˆæŠ¥å‘Š", variant="primary")
                            btn_clear = gr.Button("æ¸…ç©ºå†å²", variant="secondary")

                with gr.Column(scale=2):
                    with gr.Group(elem_classes=["result-section"]):
                        gr.Markdown("### ğŸ“„ ç»¼åˆæ£€æµ‹æŠ¥å‘Š")
                        report_output = gr.Markdown(
                            label="",
                            value="ç‚¹å‡»'ç”Ÿæˆç»¼åˆæŠ¥å‘Š'æŸ¥çœ‹ç»Ÿè®¡æ•°æ®å’Œåˆ†æ"
                        )

                        with gr.Group(elem_classes=["pdf-download-card"]):
                            gr.Markdown("### ğŸ“¥ æŠ¥å‘Šä¸‹è½½")
                            pdf_download = gr.File(
                                label="ä¸‹è½½æ£€æµ‹æŠ¥å‘Š",
                                file_types=[".pdf", ".txt"],
                                visible=False
                            )


    # ç»‘å®šäº‹ä»¶å¤„ç†
    def update_stats_with_brightness(img, threshold, brightness_factor, area_info, enable_guidance):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å’Œæ£€æµ‹çŠ¶æ€ï¼ˆå¸¦äº®åº¦è°ƒèŠ‚ï¼‰"""
        result = fast_inference_with_brightness(img, threshold, brightness_factor, area_info, enable_guidance)
        if result[0] is not None:
            detection_text = result[1]
            if "æ£€æµ‹åˆ°" in detection_text:
                stats = detection_text.split('\n')[0]
                status = update_detection_status()
                return result + (stats, status)
        status = update_detection_status()
        return result + ("ç­‰å¾…æ£€æµ‹...", status)


    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ£€æµ‹å‡½æ•°
    btn_detect.click(
        update_stats_with_brightness,
        inputs=[in_img, threshold, brightness_slider, area_info, enable_guidance],
        outputs=[out_img, out_detection, out_guidance, brightness_histogram, stats_display, detection_status]
    )


    btn_question.click(
        handle_question_with_context,
        inputs=[question_input, enable_voice_answer, generate_kg],
        outputs=[answer_output, voice_answer_audio, kg_status]
    )

    btn_voice_question.click(
        handle_voice_question_with_context,
        inputs=[voice_input, enable_voice_answer, generate_kg],
        outputs=[answer_output, voice_answer_audio, kg_status, voice_question_text]
    )

    btn_refresh_status.click(
        update_detection_status,
        outputs=[detection_status]
    )


    # çŸ¥è¯†å›¾è°±åº“äº‹ä»¶å¤„ç†
    def refresh_kg_gallery():
        """åˆ·æ–°çŸ¥è¯†å›¾è°±ç”»å»Š"""
        gallery_data, status = get_knowledge_graph_gallery()
        return gallery_data, status


    def clear_kg_history():
        """æ¸…ç©ºçŸ¥è¯†å›¾è°±å†å²"""
        global knowledge_graph_history
        # åˆ é™¤æ‰€æœ‰çŸ¥è¯†å›¾è°±æ–‡ä»¶
        for record in knowledge_graph_history:
            try:
                if os.path.exists(record['kg_image']):
                    os.remove(record['kg_image'])
            except:
                pass
        knowledge_graph_history = []
        return [], "çŸ¥è¯†å›¾è°±å†å²å·²æ¸…ç©º"


    def on_gallery_select(evt: gr.SelectData):
        """å¤„ç†ç”»å»Šé€‰æ‹©äº‹ä»¶"""
        if evt.index is not None and knowledge_graph_history:
            # è·å–é€‰ä¸­çš„çŸ¥è¯†å›¾è°±è®°å½•ï¼ˆç”»å»Šæ˜¯å€’åºæ˜¾ç¤ºçš„ï¼‰
            reversed_index = len(knowledge_graph_history) - 1 - evt.index
            if 0 <= reversed_index < len(knowledge_graph_history):
                record = knowledge_graph_history[reversed_index]
                question, answer, timestamp = get_knowledge_graph_detail(record['kg_image'])
                return record['kg_image'], question, answer, timestamp
        return None, "è¯·é€‰æ‹©çŸ¥è¯†å›¾è°±", "", ""


    # ç»‘å®šçŸ¥è¯†å›¾è°±åº“äº‹ä»¶
    btn_refresh_gallery.click(
        refresh_kg_gallery,
        outputs=[kg_gallery, gallery_status]
    )

    btn_clear_kg_history.click(
        clear_kg_history,
        outputs=[kg_gallery, gallery_status]
    )

    kg_gallery.select(
        on_gallery_select,
        outputs=[selected_kg_image, selected_question, selected_answer, selected_timestamp]
    )

    # åˆå§‹åŒ–æ—¶åˆ·æ–°ç”»å»Š
    demo.load(
        refresh_kg_gallery,
        outputs=[kg_gallery, gallery_status]
    )

    for btn in preset_buttons:
        btn.click(
            lambda q=btn.value: q,
            outputs=[question_input]
        )
    for btn in preset_buttons:
        btn.click(
            lambda q=btn.value: q,
            outputs=[question_input]
        )


    def generate_report_with_pdf(area_info, date_range):
        """ç”ŸæˆæŠ¥å‘Šå¹¶åˆ›å»ºPDF"""
        report, pdf_path = generate_comprehensive_report(area_info, date_range)
        if pdf_path:
            return report, gr.File(value=pdf_path, visible=True)
        else:
            return report, gr.File(visible=False)


    btn_report.click(
        generate_report_with_pdf,
        inputs=[report_area, date_filter],
        outputs=[report_output, pdf_download]
    )


    def clear_history_with_update():
        """æ¸…ç©ºå†å²å¹¶æ›´æ–°ç•Œé¢"""
        msg, _ = clear_history()
        return msg, gr.File(visible=False)


    btn_clear.click(
        clear_history_with_update,
        outputs=[report_output, pdf_download]
    )

if __name__ == "__main__":
    try:
        print("ğŸš€ å¯åŠ¨æ™ºèƒ½å†œä¸šåŠ©æ‰‹ç³»ç»Ÿ...")
        print("ğŸ“± è®¿é—®åœ°å€: http://localhost:7860")
        print("ğŸ§  çŸ¥è¯†å›¾è°±åŠŸèƒ½å·²å¯ç”¨")
        print("ğŸ“„ PDFæŠ¥å‘ŠåŠŸèƒ½å·²å¯ç”¨ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰")
        print("ğŸ¤ è¯­éŸ³äº¤äº’é—®ç­”åŠŸèƒ½å·²å¯ç”¨")
        print("ğŸ“Š æ£€æµ‹æ•°æ®ä¸Šä¸‹æ–‡åŠŸèƒ½å·²é›†æˆ")
        print("ğŸ§¹ AIæ€è€ƒè¿‡ç¨‹æ¸…ç†åŠŸèƒ½å·²å¯ç”¨")
        print("âš¡ æ€§èƒ½ä¼˜åŒ–å·²å¯ç”¨ï¼ˆçº¿ç¨‹ã€ç¼“å­˜ã€æ¸…ç†ï¼‰")

        # é¢„åŠ è½½å­—ä½“
        get_fonts()

        # å¯åŠ¨æ—¶æ¸…ç†
        cleanup_old_files()

        demo.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=False,
            show_error=True,
            debug=False,
            quiet=True,
            prevent_thread_lock=False
        )
    except Exception as e:
        print(f"å¯åŠ¨å¤±è´¥: {e}")
